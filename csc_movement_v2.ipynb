{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBNM0zy1/a6WdV/7szQ/W2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imj2185/csc_movement/blob/master/csc_movement_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAGQkofIuYOJ"
      },
      "outputs": [],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import argparse\n",
        "import xlsxwriter"
      ],
      "metadata": {
        "id": "A3a3TJj8uepa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "FrIKsUDqugJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DEDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, scale_data=False):\n",
        "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
        "            #Apply scaling if necessary\n",
        "            if scale_data:\n",
        "                X = StandardScaler().fit_transform(X)\n",
        "            self.X = torch.from_numpy(X)\n",
        "            self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]"
      ],
      "metadata": {
        "id": "NxECI8L3uhsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(25, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(32, 2) # 37 + 5\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "Kj_78-tkumxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Simple1DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simple1DCNN, self).__init__()\n",
        "        self.layer1 = nn.Conv1d(in_channels=1, out_channels=20, kernel_size=5)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.layer2 = nn.Conv1d(in_channels=20, out_channels=10, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.layer2(x)"
      ],
      "metadata": {
        "id": "C5MXQnRKj7-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size, kernel_size=5, stride=1, padding=2):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, 8, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv2 = nn.Conv1d(8, 16, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.fc1 = nn.Linear(16*25, 128)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(128, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rrZGld5dkAoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceRegressor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(SequenceRegressor, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)\n",
        "        # Initialize hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate the input through the LSTM layers\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # Pass the final hidden state through the fully connected layer\n",
        "        out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "wb8fQHcwkGP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def excel_to_list(exp_number, DE_list, de_scale, xls_list, tilt_scale, val=False):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in xls_list:\n",
        "        xls = pd.ExcelFile('./train_' + str(exp_number) + '/' + i)\n",
        "\n",
        "        for k, de in enumerate(DE_list):\n",
        "            azimuth = []\n",
        "            df = pd.read_excel(xls, 'DE'+str(k*de_scale)) if not val else pd.read_excel(xls, DE_list[k])\n",
        "\n",
        "            tilt_angle = [i*tilt_scale for i in range(int(360/tilt_scale))] if not val else [i for i in range(int(360/tilt_scale))]\n",
        "            for i in tilt_angle:\n",
        "                azimuth.append(df[i].values)\n",
        "\n",
        "            for i in range(len(tilt_angle)):\n",
        "                tilt = (tilt_angle[i] * math.pi) / 180.0 if not val else (tilt_angle[i] * tilt_scale  * math.pi) / 180.0\n",
        "                de_norm = float(de_scale * k) / 100.0\n",
        "                tilt_angle[i] = [tilt, de_norm]\n",
        "\n",
        "            X = X + azimuth\n",
        "            y = y + tilt_angle\n",
        "    \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    y = y.astype(float)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "1GnCE7YfkJnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_number=1\n",
        "val_number=4\n",
        "val_count=51\n",
        "sample_name='Xylem10%'\n",
        "train=True\n",
        "test=False\n",
        "\n",
        "mlp = MLP()"
      ],
      "metadata": {
        "id": "epOeML9Suoer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Load dataset\n",
        "train_DE_list = [0, 25, 50, 75, 100]\n",
        "train_xls = ['train_'+str(i) + '.xlsx' for i in range(101)]\n",
        "\n",
        "X, y = excel_to_list(exp_number, train_DE_list, 25, train_xls, 10)\n",
        "\n",
        "# Prepare dataset\n",
        "train_dataset = DEDataset(X, y)\n",
        "\n",
        "val_DE_list = ['A', 'B', 'C']\n",
        "#val_DE_list = [0, 25, 50, 75, 100]\n",
        "\n",
        "val_xls = ['val' + str(val_number) + '.xlsx']\n",
        "\n",
        "X, y = excel_to_list(exp_number, val_DE_list, 50, val_xls, 15, True)\n",
        "#X, y = excel_to_list(exp_number, val_DE_list, 25, val_xls, 10)\n",
        "valid_dataset = DEDataset(X, y)\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "validloader = DataLoader(valid_dataset, batch_size=24, shuffle=False)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_function = nn.L1Loss()\n",
        "#loss_function = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
        "\n",
        "best_loss = 100.0\n",
        "#mlp.to('cuda')\n",
        "mlp.train()\n",
        "# Run the training loop\n",
        "for epoch in range(0, 50): # 5 epochs at maximum\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "    for i, data in enumerate(trainloader):\n",
        "\n",
        "    # Get and prepare inputs\n",
        "        inputs, targets = data\n",
        "        inputs, targets = inputs.double(), targets.double()\n",
        "\n",
        "        # Perform forward pass\n",
        "        outputs = mlp(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform optimization\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        \n",
        "    if epoch % 1 == 0:\n",
        "        cur_loss = (current_loss / len(trainloader))\n",
        "        #print('Train Loss after epoch %5d: %.12f' % (epoch, cur_loss))\n",
        "        mlp.eval()\n",
        "        val_current_loss = 0.0\n",
        "        for i, data in enumerate(validloader):\n",
        "            inputs, targets = data\n",
        "            inputs, targets = inputs.double(), targets.double()\n",
        "            outputs = mlp(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            val_loss = loss_function(outputs, targets)\n",
        "            val_current_loss += val_loss.item()\n",
        "\n",
        "        val_cur_loss = (val_current_loss / len(validloader))\n",
        "\n",
        "        if best_loss > val_cur_loss:\n",
        "            best_loss = val_cur_loss\n",
        "            print('save model after epoch %5d: %.12f' % (epoch, best_loss))\n",
        "            torch.save(mlp.state_dict(), './train_' + str(exp_number)+ '/best_checkpoint.bin')\n",
        "\n",
        "    current_loss = 0.0\n",
        "\n",
        "# Process is complete.\n",
        "print('Training process has finished.')"
      ],
      "metadata": {
        "id": "SrdajJR7zam5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "1ae11d7d-2453-4ad7-a76a-7ed19868231e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5eccb4529975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'MLP' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xls = pd.ExcelFile('./train_' + str(exp_number)+ '/val' + str(val_number)+ '.xlsx')\n",
        "df2 = pd.read_excel(xls, sample_name)\n",
        "\n",
        "sample_count = val_count\n",
        "y = [0 for i in range(sample_count)]\n",
        "X = []\n",
        "\n",
        "for i in range(sample_count):\n",
        "    # X.append(df2[i].values)\n",
        "    X.append(df2[i].values)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "y = y.astype(float)\n",
        "\n",
        "dataset = DEDataset(X, y)\n",
        "testloader = DataLoader(dataset, batch_size=val_count, shuffle=False)\n",
        "\n",
        "mlp.load_state_dict(torch.load('./train_' + str(exp_number)+ '/best_checkpoint.bin'))\n",
        "mlp.eval()\n",
        "\n",
        "workbook = xlsxwriter.Workbook('train_' + str(exp_number) + '_' + sample_name + '.xlsx')\n",
        "worksheet = workbook.add_worksheet(sample_name)\n",
        "row = 0\n",
        "col = 0\n",
        "\n",
        "for i, data in enumerate(testloader):\n",
        "    # Get and prepare inputs\n",
        "    inputs, targets = data\n",
        "    inputs, targets = inputs.double(), targets.double()\n",
        "    targets = targets.reshape((targets.shape[0], 1))\n",
        "\n",
        "    # Perform forward pass\n",
        "    outputs = mlp(inputs)\n",
        "    #print(inputs)\n",
        "    angles = (outputs[:, :1] * 180.0) / math.pi # angle\n",
        "    des = (outputs[:, 1:2]) * 100.0             # DE\n",
        "\n",
        "    for i, tup in enumerate(zip(angles, des)):\n",
        "        print(tup[0].item(), tup[1].item())\n",
        "        worksheet.write(row, col, tup[0].item())\n",
        "        worksheet.write(row, col + 1, tup[1].item())\n",
        "        row += 1\n",
        "\n",
        "workbook.close()"
      ],
      "metadata": {
        "id": "nuc6Rc_vzmVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMrm9KEzzc5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}